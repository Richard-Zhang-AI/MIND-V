#!/usr/bin/env python3
"""
å¢å¼ºæç¤ºè¯ç”Ÿæˆå™¨ - Enhanced Prompt Generator
ä¸ºæœºæ¢°è‡‚æ“ä½œä»»åŠ¡ç”Ÿæˆä¼˜åŒ–çš„æ­£å‘å’Œè´Ÿå‘æç¤ºè¯

Enhanced Prompt Generator for Robotic Arm Manipulation Tasks
Generates optimized positive and negative prompts for robotic operations
"""

import os
import json
import time
from typing import Dict, List, Optional, Tuple
from loguru import logger

from vlm_api.gemini_api import call_gemini_api


class EnhancedPromptGenerator:
    """
    å¢å¼ºæç¤ºè¯ç”Ÿæˆå™¨
    è´Ÿè´£ä¸ºé•¿ç¨‹æœºæ¢°è‡‚ä»»åŠ¡ç”Ÿæˆä¼˜åŒ–çš„æç¤ºè¯
    """

    def __init__(self,
                 gemini_model="gemini-2.5-flash",
                 gemini_region="us-central1",
                 gemini_project="captioner-test-1017",
                 gemini_credential_file="/data/rczhang/MIND-V/vlm_api/captioner.json"):
        """
        åˆå§‹åŒ–å¢å¼ºæç¤ºè¯ç”Ÿæˆå™¨

        Args:
            gemini_model: Geminiæ¨¡å‹åç§°
            gemini_region: Google CloudåŒºåŸŸ
            gemini_project: é¡¹ç›®ID
            gemini_credential_file: å‡­è¯æ–‡ä»¶è·¯å¾„
        """
        self.gemini_model = gemini_model
        self.gemini_region = gemini_region
        self.gemini_project = gemini_project
        self.gemini_credential_file = gemini_credential_file

        logger.info("Enhanced Prompt Generator initialized")

    def _call_gemini_with_context(self, prompt: str, image_path: Optional[str] = None) -> str:
        """
        è°ƒç”¨Gemini APIï¼Œå¸¦æœ‰ç³»ç»Ÿä¸Šä¸‹æ–‡
        """
        # æ„å»ºå®Œæ•´çš„æç¤ºè¯ï¼ŒåŒ…å«ç³»ç»Ÿä¸Šä¸‹æ–‡
        full_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœºæ¢°è‡‚æ“ä½œè§†é¢‘ç”ŸæˆAIåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸ºé•¿ç¨‹æœºæ¢°è‡‚æ“ä½œç”Ÿæˆä¼˜åŒ–çš„æç¤ºè¯ã€‚

## ä½ çš„æ ¸å¿ƒèŒè´£ï¼š
1. ç†è§£å¤æ‚çš„æœºæ¢°è‡‚æ“ä½œæŒ‡ä»¤
2. å°†å…¶åˆ†è§£ä¸ºæœ‰åºçš„å­ä»»åŠ¡
3. ä¸ºæ¯ä¸ªå­ä»»åŠ¡ç”Ÿæˆä¼˜åŒ–çš„æ­£å‘å¼•å¯¼è¯å’Œè´Ÿå‘æç¤ºè¯
4. ç¡®ä¿è§†é¢‘ç”Ÿæˆè´¨é‡ï¼Œé¿å…å¸¸è§çš„ç”Ÿæˆé—®é¢˜

## æœºæ¢°è‡‚æ“ä½œçš„åŸºæœ¬åŸåˆ™ï¼š
- æ“ä½œåº”è¯¥è‡ªç„¶æµç•…ï¼Œç¬¦åˆç‰©ç†è§„å¾‹
- åŠ¨ä½œåº”è¯¥ç²¾ç¡®ã€ç¨³å®šï¼Œé¿å…æŠ–åŠ¨
- è½¨è¿¹åº”è¯¥åˆç†ï¼Œé¿å…ç¢°æ’å’Œå¼‚å¸¸è·¯å¾„
- æ“ä½œå¯¹è±¡åº”è¯¥ä¿æŒæ¸…æ™°çš„è¯†åˆ«åº¦

## è§†é¢‘ç”Ÿæˆè´¨é‡è¦æ±‚ï¼š
- ç”»é¢æ¸…æ™°åº¦é«˜ï¼Œç»†èŠ‚ä¸°å¯Œ
- åŠ¨ä½œæµç•…ï¼Œå¸§ç‡ç¨³å®š
- å…‰ç…§è‡ªç„¶ï¼Œè‰²å½©çœŸå®
- é¿å…ç•¸å˜ã€æ¨¡ç³Šã€ä¼ªå½±ç­‰é—®é¢˜
- èƒŒæ™¯åº”è¯¥åˆç†ï¼Œä¸åœºæ™¯åè°ƒ

## å¸¸è§éœ€è¦é¿å…çš„é—®é¢˜ï¼ˆå›ºå®šè´Ÿå‘æç¤ºè¯ï¼‰ï¼š
- Worst quality, object deformation, normal quality, low quality
- low resolution, blurry, distorted, wrong, sketch, duplicate
- ugly, monochrome, horror, geometric shapes, mutation, disgusting
- poor anatomy, disproportionate, inferior, malformed
- out of frame, out of focus, shriveled, disfigured
- extra mechanical arms, odd proportions, jpeg

{prompt}
"""

        try:
            response = call_gemini_api(
                prompt=full_prompt,
                image_path=image_path,
                model=self.gemini_model,
                region=self.gemini_region,
                project=self.gemini_project,
                credential_file=self.gemini_credential_file,
                temperature=0.1,
                seed=42
            )
            return response
        except Exception as e:
            logger.error(f"Gemini API call failed: {str(e)}")
            return None

    def generate_enhanced_prompts_for_task(self, instruction: str, image_path: str) -> Dict[str, any]:
        """
        ä¸ºæ•´ä¸ªé•¿ç¨‹ä»»åŠ¡ç”Ÿæˆå¢å¼ºçš„æç¤ºè¯

        Args:
            instruction: ç”¨æˆ·çš„å¤æ‚æŒ‡ä»¤
            image_path: è¾“å…¥å›¾åƒè·¯å¾„

        Returns:
            åŒ…å«ä»»åŠ¡åˆ†è§£å’Œæç¤ºè¯çš„å­—å…¸
        """
        logger.info(f"Generating enhanced prompts for task: {instruction}")

        # æ­¥éª¤1ï¼šåˆ†æä»»åŠ¡å¹¶åˆ†è§£
        task_decomposition_prompt = f"""
è¯·åˆ†æä»¥ä¸‹æœºæ¢°è‡‚æ“ä½œä»»åŠ¡å¹¶åˆ†è§£ä¸ºé«˜å±‚å­ä»»åŠ¡ï¼š

åŸå§‹æŒ‡ä»¤ï¼š{instruction}
åœºæ™¯å›¾åƒï¼šå·²æä¾›

åˆ†è§£åŸåˆ™ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
1. æ§åˆ¶åœ¨1-3ä¸ªé«˜å±‚å­ä»»åŠ¡ï¼Œå°½é‡å°‘è€Œå®Œæ•´ï¼›ä¸è¦å°†ä¸€ä¸ªè‡ªç„¶åŠ¨ä½œæ‹†æˆâ€œæŠ“å–/ç§»åŠ¨/æ”¾ç½®â€ç­‰å¾®æ­¥éª¤ã€‚
2. æ¯ä¸ªå­ä»»åŠ¡å¿…é¡»æ˜¾å¼åŒ…å«ï¼šåŠ¨ä½œåŸè¯­(ActionType) + å¯¹è±¡(Object) + ç›®æ ‡ä½ç½®/å®¹å™¨(Destination)ã€‚ä¾‹å¦‚â€œæŠŠXæ”¾å…¥Yâ€ã€â€œå°†Xç§»åŠ¨åˆ°Yâ€ã€â€œå°†Xç§»å‡ºç”»é¢â€ã€‚å¦‚ç›®æ ‡ç¼ºçœï¼Œè¯·æ˜ç¡®å†™ä¸ºâ€œç”»é¢å¤–/åŸä½â€ç­‰ï¼Œå¹¶åœ¨ä¸‹é¢ç»“æ„åŒ–å­—æ®µä¸­å°† destination è®¾ä¸º nullã€‚
3. å­ä»»åŠ¡æŒ‰è‡ªç„¶é¡ºåºæ’åˆ—ï¼Œå¯¹åº”â€œå†/ç„¶å/æ¥ç€â€ç­‰é€»è¾‘è¿æ¥ã€‚
4. æ¯ä¸ªå­ä»»åŠ¡å¿…é¡»â€œç‹¬ç«‹å®Œæ•´â€ï¼Œä¸å¾—åœ¨åŒä¸€å­—ç¬¦ä¸²ä¸­ç»§ç»­åŒ…å«â€œå†/ç„¶å/æ¥ç€/å¹¶ä¸”/åŒæ—¶â€ç­‰è¿æ¥è¯ï¼›è‹¥å­˜åœ¨æ­¤ç±»è¿æ¥ï¼Œè¯·æ‹†åˆ†æˆä¸¤æ¡ã€‚

Few-shot ç¤ºä¾‹ï¼š
- è¾“å…¥: "æŠŠç™½æŸ„è˜‘è‡ç©å…·æ”¾å…¥é‡‘å±é”…ä¸­"
  è¾“å‡º: [
    {{
      "original_subtask": "æŠŠç™½æŸ„è˜‘è‡ç©å…·æ”¾å…¥é‡‘å±é”…ä¸­",
      "action": "æŠ“å–å¹¶æ”¾ç½®",
      "object": "ç™½æŸ„è˜‘è‡ç©å…·",
      "destination": "é‡‘å±é”…",
      "positive_prompt": "...",
      "negative_prompt": "..."
    }}
  ]

- è¾“å…¥: "æŠŠå·¦è¾¹çš„å‹ºå­æ”¾è¿›é”…é‡Œï¼Œå†æŠŠè“è‰²æŠ¹å¸ƒæ”¾è¿›é”…é‡Œï¼Œå†æŠŠé”…æ‹¿å‡ºç”»é¢"
  è¾“å‡º: [
    {{
      "original_subtask": "æŠŠå·¦è¾¹çš„å‹ºå­æ”¾è¿›é”…é‡Œ",
      "action": "æŠ“å–å¹¶æ”¾ç½®",
      "object": "å·¦è¾¹çš„å‹ºå­",
      "destination": "é”…",
      "positive_prompt": "...",
      "negative_prompt": "..."
    }},
    {{
      "original_subtask": "æŠŠè“è‰²æŠ¹å¸ƒæ”¾è¿›é”…é‡Œ",
      "action": "æŠ“å–å¹¶æ”¾ç½®",
      "object": "è“è‰²æŠ¹å¸ƒ",
      "destination": "é”…",
      "positive_prompt": "...",
      "negative_prompt": "..."
    }},
    {{
      "original_subtask": "æŠŠé”…æ‹¿å‡ºç”»é¢",
      "action": "æŠ“å–å¹¶ç§»åŠ¨å‡ºç”»é¢",
      "object": "é”…",
      "destination": "ç”»é¢å¤–",
      "positive_prompt": "...",
      "negative_prompt": "..."
    }}
  ]

è¦æ±‚ï¼š
- è¾“å‡ºä¸ºJSONæ•°ç»„ï¼Œæ•°ç»„å…ƒç´ ä¸ºå¯¹è±¡ï¼Œå¿…é¡»åŒ…å«å­—æ®µï¼š
  - original_subtask: å­ä»»åŠ¡åŸæ–‡ï¼ˆåŠ¨ä½œ+å¯¹è±¡+ç›®æ ‡ çš„ä¸­æ–‡çŸ­å¥ï¼‰
  - action: åŠ¨ä½œåŸè¯­ï¼ˆå¦‚â€œæŠ“å–å¹¶æ”¾ç½®â€ã€â€œæŠ“å–å¹¶ç§»åŠ¨åˆ°ç›®æ ‡åŒºåŸŸâ€ã€â€œæŠ“å–å¹¶æŠ¬èµ·â€ç­‰ï¼Œéœ€ç®€æ´ç¨³å®šï¼‰
  - object: è¢«æ“ä½œçš„å®ä½“åç§°ï¼ˆå¦‚â€œæ¯›å·¾â€ã€â€œå·¦è¾¹çš„å‹ºå­â€ï¼‰
  - destination: ç›®æ ‡ä½ç½®/å®¹å™¨ï¼›è‹¥æœ‰æ˜ç¡®ç›®æ ‡ç‰©ä½“æˆ–åŒºåŸŸï¼Œå†™æˆç®€æ´åè¯çŸ­è¯­ï¼ˆå¦‚â€œé‡‘å±é”…â€ã€â€œæ¡Œå­å³ä¾§åŒºåŸŸâ€ï¼‰ï¼›è‹¥æ— æ˜ç¡®ç›®æ ‡ï¼Œåˆ™ä¸¥æ ¼å†™ä¸º null
  - positive_prompt: é’ˆå¯¹è¯¥å­ä»»åŠ¡çš„è§†é¢‘æ­£å‘æç¤ºè¯ï¼ˆä¸­æ–‡å­—ç¬¦ä¸²ï¼‰
  - negative_prompt: é’ˆå¯¹è¯¥å­ä»»åŠ¡çš„è§†é¢‘è´Ÿå‘æç¤ºè¯ï¼ˆä¸­æ–‡å­—ç¬¦ä¸²ï¼‰
- original_subtask å¿…é¡»ç‹¬ç«‹å®Œæ•´ï¼Œä¸å«â€œå†/ç„¶å/æ¥ç€/å¹¶ä¸”/åŒæ—¶â€ç­‰è¿æ¥è¯ã€‚
- destination å­—æ®µåœ¨ JSON ä¸­å¿…é¡»å‡ºç°ï¼›æ²¡æœ‰æ˜ç¡®ç»ˆç‚¹æ—¶å¿…é¡»è®¾ç½®ä¸º nullï¼ˆä¸è¦ä½¿ç”¨ç©ºå­—ç¬¦ä¸²ã€\"æ— \"ã€\"None\"ã€\"N/A\" ç­‰ï¼‰ã€‚
- è¯·åªè¿”å›ç¬¦åˆä¸Šè¿°ç»“æ„çš„ JSON æ•°ç»„ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–è§£é‡Šæ–‡å­—æˆ–æ³¨é‡Šã€‚
"""

        # å‘é€è¯·æ±‚
        response = self._call_gemini_with_context(task_decomposition_prompt, image_path)
        if not response:
            logger.error("Failed to get enhanced task decomposition from AI")
            return self._fallback_response(instruction)

        logger.info(f"Enhanced task decomposition received: {response[:100]}...")

        # è§£æå¢å¼ºå­ä»»åŠ¡
        try:
            enhanced_subtasks = self._parse_enhanced_subtasks_response(response)
            logger.info(f"Enhanced task decomposition completed: {len(enhanced_subtasks)} subtasks")
        except Exception as e:
            logger.error(f"Failed to parse enhanced subtasks: {str(e)}")
            return self._fallback_response(instruction)

        # æ„å»ºæœ€ç»ˆç»“æœ
        result = {
            "success": True,
            "original_instruction": instruction,
            "task_analysis": response,
            "subtasks": enhanced_subtasks,
            "total_subtasks": len(enhanced_subtasks),
            "enhanced_by_ai": True
        }

        logger.info(f"Enhanced prompt generation completed for {len(enhanced_subtasks)} subtasks")
        return result

    def _generate_single_task_prompts(self, subtask: str, task_index: int) -> Dict[str, str]:
        """
        ä¸ºå•ä¸ªå­ä»»åŠ¡ç”Ÿæˆä¼˜åŒ–çš„æ­£å‘å’Œè´Ÿå‘æç¤ºè¯

        Args:
            subtask: å­ä»»åŠ¡æè¿°
            task_index: ä»»åŠ¡ç´¢å¼•

        Returns:
            åŒ…å«å¢å¼ºæç¤ºè¯çš„å­—å…¸
        """
        logger.info(f"Generating enhanced prompts for subtask {task_index}: {subtask}")

        prompt_request = f"""
ç°åœ¨è¯·ä¸ºç¬¬{task_index}ä¸ªå­ä»»åŠ¡ç”Ÿæˆä¼˜åŒ–çš„è§†é¢‘ç”Ÿæˆæç¤ºè¯ï¼š

å­ä»»åŠ¡ï¼š{subtask}

è¯·ç”Ÿæˆä»¥ä¸‹å†…å®¹ï¼š

1. **æ­£å‘å¼•å¯¼è¯ï¼ˆPositive Promptï¼‰**ï¼š
   - åŸºäºåŸå­ä»»åŠ¡ï¼Œé€‚å½“æ‰©å±•æè¿°
   - æ·»åŠ åŠ¨ä½œç»†èŠ‚ã€ç¯å¢ƒæè¿°ã€è´¨é‡è¦æ±‚
   - ç¡®ä¿æç¤ºè¯å…·ä½“ã€ç”ŸåŠ¨ã€ä¸“ä¸š
   - é•¿åº¦é€‚ä¸­ï¼ˆ50-100å­—ï¼‰

2. **è´Ÿå‘æç¤ºè¯ï¼ˆNegative Promptï¼‰**ï¼š
   - é’ˆå¯¹è¿™ä¸ªå…·ä½“ä»»åŠ¡ï¼ŒæŒ‡å‡ºéœ€è¦é¿å…çš„é—®é¢˜
   - åŒ…æ‹¬è´¨é‡ã€åŠ¨ä½œã€ç‰©ä½“ã€èƒŒæ™¯ç­‰æ–¹é¢çš„è´Ÿé¢æè¿°
   - ç¡®ä¿è´Ÿå‘æç¤ºè¯ç²¾ç¡®ç›¸å…³
   - é•¿åº¦é€‚ä¸­ï¼ˆ30-60å­—ï¼‰

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{{
    "positive_prompt": "å…·ä½“çš„æ­£å‘å¼•å¯¼è¯",
    "negative_prompt": "å…·ä½“çš„è´Ÿå‘æç¤ºè¯"
}}

è¦æ±‚ï¼š
- æ­£å‘æç¤ºè¯è¦ä½“ç°ä¸“ä¸šæœºæ¢°è‡‚æ“ä½œçš„ç‰¹ç‚¹
- è´Ÿå‘æç¤ºè¯è¦é’ˆå¯¹å…·ä½“ä»»åŠ¡ï¼Œé¿å…æ³›æ³›è€Œè°ˆ
- ä¸¤ä¸ªæç¤ºè¯éƒ½è¦ç”¨ä¸­æ–‡
- è¯·åªè¿”å›JSONï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šæ–‡å­—
"""

        response = self._call_gemini_with_context(prompt_request)
        if not response:
            logger.warning(f"Failed to generate enhanced prompts for subtask {task_index}")
            return self._fallback_single_task_prompts(subtask, task_index)

        # è§£ææç¤ºè¯å“åº”
        try:
            prompts = self._parse_prompts_response(response)
            logger.info(f"Generated enhanced prompts for subtask {task_index}")
            return prompts
        except Exception as e:
            logger.error(f"Failed to parse prompts for subtask {task_index}: {str(e)}")
            return self._fallback_single_task_prompts(subtask, task_index)

    def _parse_subtasks_response(self, response: str) -> List[str]:
        """è§£æå­ä»»åŠ¡å“åº”"""
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬
            response = response.strip()

            # å¦‚æœåŒ…å«```jsonæ ‡è®°ï¼Œæå–JSONéƒ¨åˆ†
            if '```json' in response:
                start = response.find('```json') + 7
                end = response.find('```', start)
                if end != -1:
                    response = response[start:end].strip()

            # è§£æJSON
            parsed = json.loads(response)

            if isinstance(parsed, list):
                subtasks = []
                for item in parsed:
                    if isinstance(item, str) and item.strip():
                        subtasks.append(item.strip())
                return subtasks
            else:
                raise ValueError("Response is not a JSON array")

        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"Parse error: {str(e)}")
            raise

    def _parse_enhanced_subtasks_response(self, response: str) -> List[Dict[str, str]]:
        """è§£æå¢å¼ºå­ä»»åŠ¡å“åº”"""
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬
            response = response.strip()

            # å¦‚æœåŒ…å«```jsonæ ‡è®°ï¼Œæå–JSONéƒ¨åˆ†
            if '```json' in response:
                start = response.find('```json') + 7
                end = response.find('```', start)
                if end != -1:
                    response = response[start:end].strip()

            # è§£æJSON
            parsed = json.loads(response)

            if isinstance(parsed, list):
                enhanced_subtasks = []
                for i, item in enumerate(parsed, 1):
                    if isinstance(item, dict):
                        enhanced_task = {
                            'task_id': i,
                            'original_subtask': item.get('original_subtask', f"Task {i}"),
                            'positive_prompt': item.get('positive_prompt', ''),
                            'negative_prompt': item.get('negative_prompt', ''),
                            # ç»“æ„åŒ–ä¸‰å…ƒç»„ï¼šåŠ¨ä½œ / å¯¹è±¡ / ç›®çš„åœ°
                            'action': item.get('action', '').strip() if isinstance(item.get('action', ''), str) else '',
                            'object': item.get('object', '').strip() if isinstance(item.get('object', ''), str) else '',
                            # destination å…è®¸ä¸º nullï¼›ä¿æŒåŸå§‹å€¼ï¼ˆNone æˆ– å­—ç¬¦ä¸²ï¼‰
                            'destination': item.get('destination', None)
                        }
                        enhanced_subtasks.append(enhanced_task)
                return enhanced_subtasks
            else:
                raise ValueError("Response is not a JSON array")

        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"Parse error: {str(e)}")
            raise

    def _parse_prompts_response(self, response: str) -> Dict[str, str]:
        """è§£ææç¤ºè¯å“åº”"""
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬
            response = response.strip()

            # å¦‚æœåŒ…å«```jsonæ ‡è®°ï¼Œæå–JSONéƒ¨åˆ†
            if '```json' in response:
                start = response.find('```json') + 7
                end = response.find('```', start)
                if end != -1:
                    response = response[start:end].strip()

            # è§£æJSON
            parsed = json.loads(response)

            if isinstance(parsed, dict) and 'positive_prompt' in parsed and 'negative_prompt' in parsed:
                return {
                    'positive_prompt': parsed['positive_prompt'].strip(),
                    'negative_prompt': parsed['negative_prompt'].strip(),
                    'original_subtask': '',  # å°†åœ¨è°ƒç”¨å¤„å¡«å…¥
                    'task_id': 0  # å°†åœ¨è°ƒç”¨å¤„å¡«å…¥
                }
            else:
                raise ValueError("Response does not contain required prompt fields")

        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"Parse error: {str(e)}")
            raise

    def _fallback_response(self, instruction: str) -> Dict[str, any]:
        """é™çº§å“åº”ï¼šå½“AIç”Ÿæˆå¤±è´¥æ—¶ä½¿ç”¨ç®€å•æ–¹æ³•"""
        logger.warning("Using fallback response method")

        # ç®€å•çš„è§„åˆ™åˆ†è§£
        separators = ['ï¼Œç„¶å', 'ï¼Œæ¥ç€', 'ï¼Œä¹‹å', 'ï¼Œå†', 'ï¼›']
        subtasks = [instruction]  # é»˜è®¤ä½œä¸ºå•ä¸ªä»»åŠ¡

        for sep in separators:
            if sep in instruction:
                subtasks = [task.strip() for task in instruction.split(sep) if task.strip()]
                break

        # ä¸ºæ¯ä¸ªå­ä»»åŠ¡ç”ŸæˆåŸºæœ¬æç¤ºè¯
        enhanced_subtasks = []
        for i, subtask in enumerate(subtasks, 1):
            enhanced_subtasks.append(self._fallback_single_task_prompts(subtask, i))

        return {
            "success": False,
            "original_instruction": instruction,
            "subtasks": enhanced_subtasks,
            "total_subtasks": len(enhanced_subtasks),
            "enhanced_by_ai": False,
            "fallback_used": True
        }

    def _fallback_single_task_prompts(self, subtask: str, task_index: int) -> Dict[str, str]:
        """é™çº§å•ä¸ªä»»åŠ¡æç¤ºè¯ç”Ÿæˆ"""
        return {
            "task_id": task_index,
            "original_subtask": subtask,
            "positive_prompt": f"æœºæ¢°è‡‚ç²¾å‡†æ‰§è¡Œï¼š{subtask}ã€‚åŠ¨ä½œæµç•…ç¨³å®šï¼Œè½¨è¿¹ç²¾ç¡®ï¼Œæ“ä½œä¸“ä¸šã€‚",
            "negative_prompt": "ä½åˆ†è¾¨ç‡ï¼Œç”»é¢æ¨¡ç³Šï¼ŒåŠ¨ä½œå¼‚å¸¸ï¼Œè½¨è¿¹ç•¸å˜ï¼Œç‰©ä½“å˜å½¢ï¼ŒèƒŒæ™¯ä¸åè°ƒã€‚"
        }

    def get_session_info(self) -> Dict[str, any]:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        return {
            "gemini_model": self.gemini_model,
            "gemini_region": self.gemini_region,
            "gemini_project": self.gemini_project,
            "session_active": True
        }


# def test_enhanced_prompt_generator():
#     """æµ‹è¯•å¢å¼ºæç¤ºè¯ç”Ÿæˆå™¨"""
#     print("ğŸ§ª Testing Enhanced Prompt Generator...")

#     generator = EnhancedPromptGenerator()

#     # æµ‹è¯•ç”¨ä¾‹
#     test_instruction = "æ‹¿èµ·æ¡Œå­ä¸Šçš„å‹ºå­ï¼Œç„¶åæ‹¿èµ·æ¡Œå­ä¸Šçš„ç½å­"
#     test_image = "/data/rczhang/MIND-V/demos/long_video/bridge1_s3.png"

#     if os.path.exists(test_image):
#         result = generator.generate_enhanced_prompts_for_task(test_instruction, test_image)

#         print("âœ… Enhanced prompt generation completed!")
#         print(f"ğŸ“‹ Original instruction: {result['original_instruction']}")
#         print(f"ğŸ”¢ Total subtasks: {result['total_subtasks']}")
#         print(f"ğŸ¤– AI enhanced: {result['enhanced_by_ai']}")

#         for i, subtask in enumerate(result['subtasks'], 1):
#             print(f"\nğŸ“ Subtask {i}:")
#             print(f"   Original: {subtask['original_subtask']}")
#             print(f"   Positive: {subtask['positive_prompt']}")
#             print(f"   Negative: {subtask['negative_prompt']}")
#     else:
#         print(f"âš ï¸  Test image not found: {test_image}")
#         print("Testing with text-only prompt...")
#         result = generator.generate_enhanced_prompts_for_task(test_instruction, None)
#         print("âœ… Text-only test completed!")


# if __name__ == "__main__":
#     test_enhanced_prompt_generator()
